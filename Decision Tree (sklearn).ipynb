{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c67cbf8",
   "metadata": {},
   "source": [
    "Q7. Build a Decision Tree (sklearn)\n",
    "1.\tUse sklearn.tree.DecisionTreeClassifier on the Iris dataset.\n",
    "2.\tTrain trees with max_depth = 1, 2, 3.\n",
    "3.\tReport training and test accuracy for each depth.\n",
    "4.\tDiscuss signs of underfitting vs overfitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d6f6005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Iris dataset. Train size: 105, Test size: 45\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split into train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42, stratify=y\n",
    ")\n",
    "print(f\"Loaded Iris dataset. Train size: {X_train.shape[0]}, Test size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5fcce7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth | Train Accuracy | Test Accuracy\n",
      "1     | 0.667         | 0.667\n",
      "2     | 0.971         | 0.889\n",
      "3     | 0.981         | 0.978\n"
     ]
    }
   ],
   "source": [
    "depths = [1, 2, 3]\n",
    "results = []\n",
    "\n",
    "for depth in depths:\n",
    "    clf = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # Predictions\n",
    "    y_train_pred = clf.predict(X_train)\n",
    "    y_test_pred = clf.predict(X_test)\n",
    "    \n",
    "    # Accuracy\n",
    "    train_acc = accuracy_score(y_train, y_train_pred)\n",
    "    test_acc = accuracy_score(y_test, y_test_pred)\n",
    "    \n",
    "    results.append((depth, train_acc, test_acc))\n",
    "\n",
    "# Print results\n",
    "print(\"Depth | Train Accuracy | Test Accuracy\")\n",
    "for depth, train_acc, test_acc in results:\n",
    "    print(f\"{depth:<5} | {train_acc:.3f}         | {test_acc:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b62851",
   "metadata": {},
   "source": [
    "4. Discussion: Underfitting vs. Overfitting\n",
    "\n",
    "Depth = 1 (Underfitting)\n",
    "\n",
    "The tree is very shallow and can only make very simple splits.\n",
    "\n",
    "Both training and test accuracy are relatively low.\n",
    "\n",
    "Model fails to capture the complexity of the data.\n",
    "\n",
    "Depth = 2 (Good Fit)\n",
    "\n",
    "Much better training and test accuracy.\n",
    "\n",
    "The tree captures more structure without over-complicating.\n",
    "\n",
    "Depth = 3 (Risk of Overfitting)\n",
    "\n",
    "Training accuracy nearly perfect.\n",
    "\n",
    "Test accuracy is slightly lower than training (small gap).\n",
    "\n",
    "If depth kept increasing, the gap would grow â†’ classic overfitting."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
